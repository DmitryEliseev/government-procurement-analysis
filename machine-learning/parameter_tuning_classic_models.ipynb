{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XXdxKqYewAle"
   },
   "source": [
    "# Parameters tuning with Hyperopt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QhgfIAgRwAlf"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "from gpalib import model\n",
    "\n",
    "from hyperopt import fmin, tpe, hp, Trials, STATUS_OK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "b9uhk9bewAli"
   },
   "outputs": [],
   "source": [
    "RANDOM_SEED = 42\n",
    "LOCAL = True\n",
    "PATH_TO_LOG_FILE = 'parameter_tuning_logs.txt'\n",
    "PATH_TO_ALL_HISTORY_FILE = 'parameter_tuning_all_logs.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 270
    },
    "colab_type": "code",
    "id": "Iqq19OSfwUWU",
    "outputId": "5cfbe963-843f-4458-c825-df7b4fbec897"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(308257, 187)\n"
     ]
    }
   ],
   "source": [
    "if LOCAL:\n",
    "    # If working in local environment\n",
    "    data = pd.read_csv('../data/russia-16-19-v2.5.csv')\n",
    "    print(data.shape)\n",
    "    data.head()\n",
    "else: \n",
    "    # If working in Google Colab\n",
    "    os.mkdir('gpalib')\n",
    "    os.mkdir('model')\n",
    "\n",
    "    os.rename(\"__init__.py\", \"gpalib/__init__.py\")\n",
    "    os.rename(\"analysis.py\", \"gpalib/analysis.py\")\n",
    "    os.rename(\"model.py\", \"gpalib/model.py\")\n",
    "    os.rename(\"preprocessing.py\", \"gpalib/preprocessing.py\")\n",
    "\n",
    "    data = pd.read_csv('russia-16-19-v2.5.csv')\n",
    "    print(data.shape)\n",
    "    data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uNp2108RxwHQ"
   },
   "outputs": [],
   "source": [
    "# Train / validation split in proportion 4:1\n",
    "valid_data = data.sample(frac=0.2, random_state=RANDOM_SEED)\n",
    "train_data = data.drop(valid_data.index, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For storing history of models trained\n",
    "history_storage = {\n",
    "    'model': [],\n",
    "    'params': [],\n",
    "    'score': []\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_params(params: dict):\n",
    "    \"\"\"Loging only important params\"\"\"\n",
    "    \n",
    "    def round_if_float(value):\n",
    "        \"\"\"Round float values\"\"\"\n",
    "        \n",
    "        if type(value) == float:\n",
    "            return round(value, 3)\n",
    "        else:\n",
    "            return value\n",
    "        \n",
    "    params_to_delete = ('type', 'n_jobs', 'random_state', 'verbosity')\n",
    "\n",
    "    return {\n",
    "        k: round_if_float(v) for k, v in params.items() \n",
    "        if k not in params_to_delete\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "0ySj7zJKwAlq",
    "outputId": "a767727c-610e-4f53-b63e-f8a646560140"
   },
   "outputs": [],
   "source": [
    "space = hp.choice('classifier_type', [\n",
    "    {\n",
    "        'type': 'LogReg',\n",
    "        'C': hp.uniform('C', 0, 10.0),\n",
    "        'penalty': hp.choice('penalty', ['l1', 'l2']),\n",
    "        'solver': hp.choice('solver', ['saga', 'liblinear']),\n",
    "        'n_jobs': -1,\n",
    "        'random_state': RANDOM_SEED\n",
    "    },\n",
    "    {\n",
    "        'type': 'RandForest',\n",
    "        'max_depth': hp.choice('max_depth-rf', range(1, 11)),\n",
    "        'max_features': hp.choice('max_features', np.arange(15, 31, 5).tolist() + ['log2', 'sqrt']),\n",
    "        'n_estimators': hp.choice('n_estimators-rf', range(100, 1001, 100)),\n",
    "        'criterion': hp.choice('criterion', [\"gini\", \"entropy\"]),\n",
    "        'n_jobs': -1,\n",
    "        'random_state': RANDOM_SEED\n",
    "    },\n",
    "    {\n",
    "        'type': 'XGBoost',\n",
    "        'n_estimators': hp.choice('n_estimators', range(100, 1001, 100)),\n",
    "        'eta': hp.quniform('eta', 0.025, 0.5, 0.025),\n",
    "        'max_depth':  hp.choice('max_depth', range(1, 11)),\n",
    "        'subsample': hp.quniform('subsample', 0.5, 1, 0.05),\n",
    "        'gamma': hp.quniform('gamma', 0.5, 1, 0.05),\n",
    "        'random_state': RANDOM_SEED,\n",
    "        'n_jobs': -1,\n",
    "        \"verbosity\": 0,\n",
    "    }\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "count, best = 0, -100\n",
    "\n",
    "def f(params):\n",
    "    \"\"\"Function for Hyperopt\"\"\"\n",
    "    global best, count\n",
    "    \n",
    "    count += 1\n",
    "    neg_log_los = model.hyperopt_train_test(\n",
    "        train_data,\n",
    "        params.copy(),\n",
    "        history_storage,\n",
    "        cv=2)\n",
    "    \n",
    "    if neg_log_los > best:\n",
    "        best = neg_log_los\n",
    "        out_str = 'New best: {:.5f} using {}'.format(\n",
    "            neg_log_los, \n",
    "            filter_params(params)\n",
    "        )\n",
    "        \n",
    "        print(out_str)\n",
    "        with open(PATH_TO_LOG_FILE, 'a', encoding='utf-8') as file:\n",
    "            file.write(out_str+'\\n')\n",
    "    \n",
    "    return {'loss': neg_log_los, 'status': STATUS_OK}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New best: -0.31104 using {'C': 0.435, 'penalty': 'l1', 'solver': 'saga'}\n",
      "New best: -0.19636 using {'eta': 0.375, 'gamma': 0.8, 'max_depth': 6, 'n_estimators': 700, 'subsample': 1.0}\n",
      "New best: -0.19632 using {'eta': 0.275, 'gamma': 0.7, 'max_depth': 6, 'n_estimators': 1000, 'subsample': 0.75}\n",
      "100%|██████████| 10/10 [1:20:13<00:00, 258.69s/it, best loss: -0.4700524725200869] \n"
     ]
    }
   ],
   "source": [
    "trials = Trials()\n",
    "best = fmin(f, space, algo=tpe.suggest, max_evals=10, trials=trials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving history of models tried\n",
    "with open(PATH_TO_ALL_HISTORY_FILE, 'w', encoding='utf-8') as file:\n",
    "    file.write(json.dumps(history_storage, indent=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OgtN6eAMwAlu"
   },
   "source": [
    "**Hyperopt tutorials:** \n",
    "- https://medium.com/district-data-labs/parameter-tuning-with-hyperopt-faa86acdfdce\n",
    "- https://www.kaggle.com/yassinealouini/hyperopt-the-xgboost-model\n",
    "- https://github.com/WillKoehrsen/hyperparameter-optimization/blob/master/Bayesian%20Hyperparameter%20Optimization%20of%20Gradient%20Boosting%20Machine.ipynb"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "parameter_tuning-classic-models.ipynb",
   "provenance": [],
   "toc_visible": true,
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
